{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "homeless-tracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50 documents\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "\n",
    "response = urlopen('''https://www.gutenberg.org/cache/epub/10834/pg10834.txt''')  # insects\n",
    "\n",
    "PARAGRAPH_SPLITTER = '\\r\\n\\r\\n'\n",
    "\n",
    "text = response.read().decode()\n",
    "\n",
    "text = text[text.index(\"***START OF THE PROJECT GUTENBERG\") :text.index(\"***END OF THE PROJECT GUTENBERG\")]\n",
    "\n",
    "documents = text.split(PARAGRAPH_SPLITTER)\n",
    "\n",
    "documents = list(filter(lambda x: len(x) > 25, documents))\n",
    "\n",
    "def preprocess(s):\n",
    "    return s.strip()\n",
    "\n",
    "documents =  list(map(preprocess, documents))\n",
    "\n",
    "documents = np.array(documents)\n",
    "\n",
    "print(f'There are {len(documents)} documents')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "arbitrary-baseball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This cut shews the appearance of the worm, which at first is very small\\r\\nand black. Its food is the leaves of the white mulberry: as it grows in\\r\\nsize, at four different periods, it apparently sickens, and changes its\\r\\nskin, and finally, when full grown, it spins a ball of silk, called a\\r\\ncone, or cocoon, the thread of which is about three hundred yards long:\\r\\nin the centre of this ball the worm entombs itself, and experiences a\\r\\nchange to a state called an aurelia, or chrysallis, as seen below the\\r\\nball: from this aurelia, the moth that lays the eggs is hatched, and\\r\\nthus goes on the round of this animal's changes, or transmigrations.\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample, seed\n",
    "\n",
    "seed(42)\n",
    "\n",
    "sample(sorted(documents), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "former-pitch",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y9/9xqbqkg90tnc0cmm0dxt985m0000gn/T/ipykernel_44748/706670702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# a model pre-trained on an asymmetric semantic search task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'msmarco-distilbert-base-v4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# a model pre-trained on an asymmetric semantic search task\n",
    "sbert_model = SentenceTransformer('msmarco-distilbert-base-v4')\n",
    "\n",
    "# Documents are encoded by calling model.encode()\n",
    "document_embeddings = sbert_model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model.encode(['hi'])[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = 'How many horns does a flea have?'  # a natural language query\n",
    "\n",
    "query_embedding = sbert_model.encode(QUESTION)  # embed the query into a vector space\n",
    "\n",
    "top_scores = util.cos_sim(query_embedding, document_embeddings)  # use cosine similarity to find the most relevant document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-score",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_scores.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_documents = documents[top_scores.sort().indices[0][-3:]][::-1]\n",
    "top_cosine_sim = list(top_scores.sort().values[0][-3:])[::-1]\n",
    "\n",
    "for i, (cos_sim, top_document) in enumerate(zip(top_cosine_sim, top_documents)):\n",
    "    print(f'Top Document {i + 1} Cos_Sim {cos_sim:.3f}:\\n\\n{top_document}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained('bert-base-cased')  # distilbert doesn't have token type IDs\n",
    "qa_bert = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-cased-distilled-squad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-toilet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hairy-fighter",
   "metadata": {},
   "source": [
    "# Using a pretrained model to fine-tune our answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-manual",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline('question-answering', model='distilbert-base-uncased-distilled-squad', tokenizer='distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa(question=QUESTION, context=top_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-powell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "decent-import",
   "metadata": {},
   "source": [
    "# Using our pretrained model from the last use-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "qa_bert_finetuned = BertForQuestionAnswering.from_pretrained('./qa/results')\n",
    "\n",
    "finetuned_qa = pipeline('question-answering', model=qa_bert_finetuned, tokenizer='bert-large-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_qa(question=QUESTION, context=top_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-capture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sbert.net/docs/pretrained_models.html for more fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-chain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load up the adversarial_qa dataset from the last use-case\n",
    "training_qa = load_dataset('adversarial_qa', 'adversarialQA', split='train')\n",
    "\n",
    "good_training_data = []\n",
    "bad_training_data = []\n",
    "    \n",
    "last_example = None\n",
    "for example in training_qa:\n",
    "    if last_example and example['context'] != last_example['context']:\n",
    "        bad_training_data.append((example['question'], last_example['context'], 0.0))  #  add bad examples\n",
    "    # question, context, label is 1 for these should be matched together\n",
    "    good_training_data.append((example['question'], example['context'], 1.0))\n",
    "    last_example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good_training_data), len(bad_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-hometown",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-reproduction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.sbert.net/docs/training/overview.html for information on training\n",
    "\n",
    "from sentence_transformers import InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from random import sample, seed, shuffle\n",
    "\n",
    "seed(42)  # seed our upcoming sample\n",
    "\n",
    "sampled_training_data = sample(good_training_data, 500) + sample(bad_training_data, 500)\n",
    "\n",
    "shuffle(sampled_training_data)\n",
    "\n",
    "#Define the training examples\n",
    "train_examples = [InputExample(texts=t[:2], label=t[2]) for t in sampled_training_data[:800]]\n",
    "\n",
    "\n",
    "#Define your train dataset, the dataloader and the train loss\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "train_loss = losses.CosineSimilarityLoss(sbert_model)\n",
    "\n",
    "# Evaluation data\n",
    "sentences1, sentences2, scores = zip(*sampled_training_data[800:])\n",
    "\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the model\n",
    "sbert_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)], output_path='ir/results',\n",
    "    epochs=2, warmup_steps=50, \n",
    "    evaluator=evaluator, evaluation_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-austria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-office",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fine-tuned IR model\n",
    "finetuned_sbert_model = SentenceTransformer('ir/results')\n",
    "\n",
    "finetuned_sbert_model.encode(['hi'])[0][:5]  # different embedding as before which is expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-bundle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-encode the documents and run the same question as before\n",
    "document_embeddings = finetuned_sbert_model.encode(documents)\n",
    "\n",
    "query_embedding = sbert_model.encode(QUESTION)  # embed the query into a vector space\n",
    "\n",
    "top_scores = util.cos_sim(query_embedding, document_embeddings)  # use cosine similarity to find the most relevant document\n",
    "\n",
    "top_documents = documents[top_scores.sort().indices[0][-3:]][::-1]\n",
    "top_cosine_sim = list(top_scores.sort().values[0][-3:])[::-1]\n",
    "\n",
    "for i, (cos_sim, top_document) in enumerate(zip(top_cosine_sim, top_documents)):\n",
    "    print(f'Top Document {i + 1} Cos_Sim {cos_sim:.3f}:\\n\\n{top_document}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-outreach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gutenberg_to_documents(url, sbert_model):\n",
    "    response = urlopen(url)\n",
    "\n",
    "    PARAGRAPH_SPLITTER = '\\r\\n\\r\\n'\n",
    "\n",
    "    text = response.read().decode()\n",
    "    try:\n",
    "        text = text[text.index(\"***START OF THE PROJECT GUTENBERG\") :text.index(\"***END OF THE PROJECT GUTENBERG\")]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    documents = text.split(PARAGRAPH_SPLITTER)\n",
    "\n",
    "    documents = list(filter(lambda x: len(x) > 25, documents))\n",
    "\n",
    "    def preprocess(s):\n",
    "        return s.strip()\n",
    "\n",
    "    documents =  list(map(preprocess, documents))\n",
    "\n",
    "    documents = np.array(documents)\n",
    "\n",
    "    print(f'There are {len(documents)} documents')\n",
    "    \n",
    "    return documents, sbert_model.encode(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_documents(sbert_model, query, documents, embeddings, qa=None):\n",
    "    query_embedding = sbert_model.encode(query)  # embed the query into a vector space\n",
    "\n",
    "    top_scores = util.cos_sim(query_embedding, embeddings)  # use cosine similarity to find the most relevant document\n",
    "    top_documents = documents[top_scores.sort().indices[0][-3:]][::-1]\n",
    "    top_cosine_sim = list(top_scores.sort().values[0][-3:])[::-1]\n",
    "\n",
    "    for i, (cos_sim, top_document) in enumerate(zip(top_cosine_sim, top_documents)):\n",
    "        print(f'Top Document {i + 1} Cos_Sim {cos_sim:.3f}:\\n\\n{top_document}')\n",
    "        if qa:\n",
    "            answer = qa(question=query, context=top_document)\n",
    "            print(f'\\nAnswer: {answer}\\n')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-evolution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "banks_to_bassoon_documents, banks_to_bassoon_embeddings = gutenberg_to_documents(\n",
    "    'https://www.gutenberg.org/cache/epub/27480/pg27480.txt', finetuned_sbert_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_relevant_documents(finetuned_sbert_model,\n",
    "    'What is a banshee?', banks_to_bassoon_documents, banks_to_bassoon_embeddings,\n",
    "    qa=qa\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_relevant_documents(finetuned_sbert_model,\n",
    "    'Where do you usually play amateur base ball?', banks_to_bassoon_documents, banks_to_bassoon_embeddings,\n",
    "    qa=qa\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-disease",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-darwin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

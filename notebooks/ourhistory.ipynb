{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "former-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# a model pre-trained on an asymmetric semantic search task\n",
    "sbert_model = SentenceTransformer('msmarco-distilbert-base-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coordinate-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expensive-fluid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40406635, -0.16512747, -0.09304258, -0.1626442 , -0.69411176],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_model.encode(['hi'])[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baking-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline('question-answering', model='distilbert-base-uncased-distilled-squad', tokenizer='distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-toilet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-newsletter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alert-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def url_to_documents(urls, sbert_model, MIN_LENGTH=100, splitter='auto'):\n",
    "    if type(urls) == str:\n",
    "        urls = [urls]\n",
    "        \n",
    "    documents = []\n",
    "    \n",
    "    for url in urls:\n",
    "        response = requests.get(url).text\n",
    "\n",
    "        text = BeautifulSoup(response, 'html.parser').get_text()\n",
    "        \n",
    "        if splitter == 'auto':\n",
    "            most_common = Counter(list(filter(lambda x:x !=' ', re.findall('[\\s]+', text)))).most_common(5)\n",
    "            splitter = most_common[0][0]\n",
    "            print(f'Using {most_common} as splitter')\n",
    "\n",
    "        documents += list(filter(lambda x: len(x) > MIN_LENGTH, text.split(splitter)))\n",
    "\n",
    "    def preprocess(s):\n",
    "        return s.strip()\n",
    "\n",
    "    documents =  list(map(preprocess, documents))\n",
    "\n",
    "    documents = np.array(documents)\n",
    "\n",
    "    print(f'There are {documents.shape[0]} documents')\n",
    "    \n",
    "    return documents, sbert_model.encode(documents)\n",
    "\n",
    "def retrieve_relevant_documents(sbert_model, query, documents, embeddings, qa=None):\n",
    "    query_embedding = sbert_model.encode(query)  # embed the query into a vector space\n",
    "\n",
    "    top_scores = util.cos_sim(query_embedding, embeddings)  # use cosine similarity to find the most relevant document\n",
    "    top_documents = documents[top_scores.sort().indices[0][-3:]][::-1]\n",
    "    top_cosine_sim = list(top_scores.sort().values[0][-3:])[::-1]\n",
    "\n",
    "    for i, (cos_sim, top_document) in enumerate(zip(top_cosine_sim, top_documents)):\n",
    "        print(f'Top Document {i + 1} Cos_Sim {cos_sim:.3f}:\\n\\n{top_document}')\n",
    "        if qa:\n",
    "            answered = qa(question=query, context=top_document)\n",
    "            answer, score = answered['answer'].strip(), answered['score']\n",
    "            print(f'\\nAnswer: {answer} Score: {score:.2f}\\n')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-danish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verified-pantyhose",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using [('\\n', 73), ('\\n\\xa0\\n', 5), (' \\n\\xa0\\n', 3), ('\\xa0', 2), ('\\xa0 ', 2)] as splitter\n",
      "There are 36 documents\n",
      "Top Document 1 Cos_Sim 0.740:\n",
      "\n",
      "Cranbury is one of the oldest towns in New Jersey. Settlers came from France, England, Scotland, Holland, Germany, and Norway, perhaps as early as 1680. However, the first recorded evidence of buildings in Cranbury is March 1, 1698, on a deed of sale between Josia Prickett of Burlington and John Harrison for land \"with all improvements.\" Around the same date, John Harrison also received a license to buy more land from the local Lenape Indians, a Delaware tribe.\n",
      "\n",
      "Answer: 1680 Score: 0.25\n",
      "\n",
      "\n",
      "\n",
      "Top Document 2 Cos_Sim 0.684:\n",
      "\n",
      "The Second Presbyterian Church of Cranbury was founded in 1838. In 1935 the First and Second Church congregations were joined. The Second Church sanctuary was razed and a monument erected on the site. The sexton's house remains as a residence.\n",
      "\n",
      "Answer: 1838 Score: 0.99\n",
      "\n",
      "\n",
      "\n",
      "Top Document 3 Cos_Sim 0.682:\n",
      "\n",
      "The Cranbury Public Library, founded in 1906, was housed at the former Cranbury Press building at 13 North Main Street and later at the Colonial House (formerly known as the American Hotel) on Scott Ave. In 1924 the Public Library was invited to move its facility to the Cranbury School, where it is now located in a large room in conjunction with the School Library, an arrangement unique in New Jersey.\n",
      "\n",
      "Answer: 1906 Score: 0.99\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cran_doc, cran_emb = url_to_documents(\n",
    "    'https://www.cranburyhistory.org/about-cranbury-nj', sbert_model, splitter='auto'\n",
    ")\n",
    "\n",
    "retrieve_relevant_documents(sbert_model,\n",
    "    'When was cranbury, New Jersey founded?', cran_doc, cran_emb,\n",
    "    qa=qa\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "precise-swimming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 424 documents\n"
     ]
    }
   ],
   "source": [
    "doc, emb = url_to_documents(\n",
    "    'https://www.gutenberg.org/files/17087/17087-0.txt', sbert_model, splitter='\\r\\n\\r\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "determined-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Document 1 Cos_Sim 0.644:\n",
      "\n",
      "One function, then, of art is to feed and nurture the imagination and\r\n",
      "the spirit, and thereby enhance and invigorate the whole of human life.\r\n",
      "This is far removed from the view that the end of art is to give\r\n",
      "pleasure. Art does usually cause pleasure, singular and intense, and to\r\n",
      "that which causes such pleasure we give the name of Beauty. But to\r\n",
      "produce and enjoy Beauty is not the function of art. Beauty--or rather,\r\n",
      "the sensation of Beauty--is what the Greeks would call an _epigignomenon\r\n",
      "ti telos_, words hard to translate, something between a by-product and a\r\n",
      "supervening perfection, a thing like--as Aristotle[54] for once\r\n",
      "beautifully says of pleasure--\"the bloom of youth to a healthy young\r\n",
      "body.\"\n",
      "\n",
      "Answer: to feed and nurture the imagination and\r\n",
      "the spirit Score: 0.26\n",
      "\n",
      "\n",
      "\n",
      "Top Document 2 Cos_Sim 0.614:\n",
      "\n",
      "But, though the artist's vision and emotion alike are modified,\r\n",
      "purified, they are not devitalized. Far from that, by detachment from\r\n",
      "action they are focussed and intensified. Life is enhanced, only it is a\r\n",
      "different kind of life, it is the life of the image-world, of the\r\n",
      "_imag_ination; it is the spiritual and human life, as differentiated\r\n",
      "from the life we share with animals. It is a life we all, as human\r\n",
      "beings, possess in some, but very varying, degrees; and the natural man\r\n",
      "will always view the spiritual man askance, because he is not\r\n",
      "\"practical.\" But the life of imagination, cut off from practical\r\n",
      "reaction as it is, becomes in turn a motor-force causing new emotions,\r\n",
      "and so pervading the general life, and thus ultimately becoming\r\n",
      "\"practical.\" No one function is completely cut off from another. The\r\n",
      "main function of art is probably to intensify and purify emotion, but it\r\n",
      "is substantially certain that, if we did not feel, we could not think\r\n",
      "and should not act. Still it remains true that, in artistic\r\n",
      "contemplation and in the realms of the artist's imagination not only are\r\n",
      "practical motor-reactions cut off, but intelligence is suffused in, and\r\n",
      "to some extent subordinated to, emotion.\n",
      "\n",
      "Answer: to intensify and purify emotion Score: 0.61\n",
      "\n",
      "\n",
      "\n",
      "Top Document 3 Cos_Sim 0.570:\n",
      "\n",
      "(2) The \"expression\" theory, which holds that the aim of art is to\r\n",
      "express the emotions and thoughts of the artist.\n",
      "\n",
      "Answer: to\r\n",
      "express the emotions and thoughts of the artist Score: 0.43\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieve_relevant_documents(sbert_model,'What is the purpose of art?', doc, emb, qa=qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-obligation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-mortality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-welding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-insight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-analysis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "selected-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset adversarial_qa (/Users/sinanozdemir/.cache/huggingface/datasets/adversarial_qa/adversarialQA/1.0.0/92356be07b087c5c6a543138757828b8d61ca34de8a87807d40bbc0e6c68f04b)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load up the adversarial_qa dataset from the last use-case\n",
    "training_qa = load_dataset('adversarial_qa', 'adversarialQA', split='train')\n",
    "\n",
    "good_training_data = []\n",
    "bad_training_data = []\n",
    "    \n",
    "last_example = None\n",
    "for example in training_qa:\n",
    "    if last_example and example['context'] != last_example['context']:\n",
    "        bad_training_data.append((example['question'], last_example['context'], 0.0))  #  add bad examples\n",
    "    # question, context, label is 1 for these should be matched together\n",
    "    good_training_data.append((example['question'], example['context'], 1.0))\n",
    "    last_example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8073cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2647"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaaeffa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stone-reproduction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.sbert.net/docs/training/overview.html for information on training\n",
    "\n",
    "from sentence_transformers import InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from random import sample, seed, shuffle\n",
    "\n",
    "seed(42)  # seed our upcoming sample\n",
    "\n",
    "sampled_training_data = sample(good_training_data, 2500) + sample(bad_training_data, 2500)\n",
    "\n",
    "shuffle(sampled_training_data)\n",
    "\n",
    "eighty_index = int(.8 * len(sampled_training_data))\n",
    "\n",
    "#Define the training examples\n",
    "train_examples = [InputExample(texts=t[:2], label=t[2]) for t in sampled_training_data[:eighty_index]]\n",
    "\n",
    "\n",
    "#Define your train dataset, the dataloader and the train loss\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "train_loss = losses.CosineSimilarityLoss(sbert_model)\n",
    "\n",
    "# Evaluation data\n",
    "sentences1, sentences2, scores = zip(*sampled_training_data[eighty_index:])\n",
    "\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)\n",
    "# evaluator = evaluation.BinaryClassificationEvaluator(sentences1, sentences2, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sweet-encounter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905592018146427"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_model.evaluate(evaluation.BinaryClassificationEvaluator(sentences1, sentences2, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "engaging-diagram",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fedf418b944d869b9c3eda686c3b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0c70a95f8149a68676e1740c1709e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa092e8189540cc9875e8851a0894c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00a358e9b1c45df8ad5932983af53de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tune the model\n",
    "sbert_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)], output_path='ir/results',\n",
    "    epochs=3, warmup_steps=len(train_examples) // 5, \n",
    "    evaluator=evaluator, evaluation_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "swedish-austria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149263639975689"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_model.evaluate(evaluation.BinaryClassificationEvaluator(sentences1, sentences2, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-office",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aboriginal-amount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3870701 , -0.17139037,  0.00948946, -0.13145085, -0.77764136],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load fine-tuned IR model\n",
    "finetuned_sbert_model = SentenceTransformer('ir/results')\n",
    "\n",
    "finetuned_sbert_model.encode(['hi'])[0][:5]  # different embedding as before which is expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-tourism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afraid-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 documents\n",
      "Top Document 1 Cos_Sim 0.760:\n",
      "\n",
      "Cranbury is one of the oldest towns in New Jersey. Settlers came from France, England, Scotland, Holland, Germany, and Norway, perhaps as early as 1680. However, the first recorded evidence of buildings in Cranbury is March 1, 1698, on a deed of sale between Josia Prickett of Burlington and John Harrison for land \"with all improvements.\" Around the same date, John Harrison also received a license to buy more land from the local Lenape Indians, a Delaware tribe.\n",
      "\n",
      "Answer: 1680 Score: 0.25\n",
      "\n",
      "\n",
      "\n",
      "Top Document 2 Cos_Sim 0.752:\n",
      "\n",
      "The Baptist Church in Cranbury was founded in 1745 with John Hight (Hightstown) as one of the 17 original members. The first meeting house was built in 1748 on property occupied later by the Spice Mill. The church was used for 40 years, then sold to Dr.Stites and moved. The congregation moved to Hightstown in 1785. The front part of the church grounds was sold and the burial grounds by 1882 were neglected and contained only 4 standing headstones.\n",
      "\n",
      "Answer: 1745 Score: 0.99\n",
      "\n",
      "\n",
      "\n",
      "Top Document 3 Cos_Sim 0.750:\n",
      "\n",
      "The Second Presbyterian Church of Cranbury was founded in 1838. In 1935 the First and Second Church congregations were joined. The Second Church sanctuary was razed and a monument erected on the site. The sexton's house remains as a residence.\n",
      "\n",
      "Answer: 1838 Score: 0.99\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cran_doc, cran_emb = url_to_documents(\n",
    "    'https://www.cranburyhistory.org/about-cranbury-nj', finetuned_sbert_model, splitter='\\n\\u200b\\n'\n",
    ")\n",
    "\n",
    "retrieve_relevant_documents(sbert_model, 'When was cranbury, new jersey founded?', cran_doc, cran_emb, qa=qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-moldova",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199277fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
